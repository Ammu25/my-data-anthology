{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This program scrapes CoinMarketCap.com's page to fetch the top 300 cryptocurrencies and their data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Import all the required libraries:\n",
    "1. Import selenium webdriver for scraping dynamic webpages - Javascript content\n",
    "2. Import BeautifulSoup for scraping the static pages - HTML or XML content\n",
    "3. Import pandas to create a dataframe, convert list objects into this dataframe, and then write it to an excel (.xlsx) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define empty lists to store all the scraped columns data\n",
    "\n",
    "Name=[]\n",
    "Symbol=[]\n",
    "Rank=[]\n",
    "Price=[]\n",
    "Mcap=[]\n",
    "Website=[]\n",
    "\n",
    "#Create a for loop to loop through multiple pages - 3 pages in this case\n",
    "\n",
    "for page in range(1,4,1):\n",
    "    \n",
    "    url=\"https://coinmarketcap.com/?page=\" + str(page) #url of the page to be scraped\n",
    "    \n",
    "#Selenium will access the Chrome browser driver in incognito mode (without opening a browser window (headless option))\n",
    "\n",
    "    options=webdriver.ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--incognito')\n",
    "    options.add_argument('--headless')\n",
    "    \n",
    "#Initiate the webdriver\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.maximize_window()\n",
    "    driver.get(url)\n",
    "    \n",
    "#Create a for loop to scroll to the bottom of each page to load all the hidden javascript elements   \n",
    "\n",
    "    scroll=int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    for i in range(1,scroll,800): #Maximum step to read all the elements without skipping any of it\n",
    "        driver.execute_script(\"window.scrollTo(0,{});\".format(i))\n",
    "\n",
    "#Render the JS code and store all the information in static HTML code\n",
    "\n",
    "    html = driver.page_source\n",
    "\n",
    "#Create a BeautifulSoup element for the above html variable\n",
    "\n",
    "    beu_soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "#Inspect the url to find the required table class for scraping\n",
    "\n",
    "    my_table=beu_soup.find('table', {'class':'sc-beb003d5-3 ieTeVa cmc-table '}) \n",
    "    rows = my_table.find_all('tr')[1:]\n",
    "\n",
    "#Create a for loop to loop through each row and scrape the required columns either using a class or a cell index (td)\n",
    "\n",
    "    for row in rows:\n",
    "        name=row.find('p',class_='sc-4984dd93-0 kKpPOn')\n",
    "        symbol=row.find('p',class_='sc-4984dd93-0 iqdbQL coin-item-symbol')\n",
    "        rank=row.find('div',class_='sc-8497df48-3 erCSsg')\n",
    "        price=row.find_all('td')[3]\n",
    "        mcap=row.find_all('td')[7]\n",
    "        website=row.find('a',class_='cmc-link')\n",
    "\n",
    "#Append all the variable data to their respective lists\n",
    "\n",
    "        Name.append(name.get_text())\n",
    "        Symbol.append(symbol.get_text())\n",
    "        Rank.append(rank.get_text())\n",
    "        Price.append(price.get_text())\n",
    "        Mcap.append(mcap.get_text())\n",
    "        Website.append('https://coinmarketcap.com' + website.get('href'))\n",
    "    \n",
    "    driver.close() #close the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all the lists into a dataframe\n",
    "\n",
    "df=pd.DataFrame(list(zip(Rank, Name, Symbol, Price, Mcap, Website)),\n",
    "              columns=['Rank based on Market Cap', 'Name', 'Symbol', 'Price', 'Market_Capital', 'Website'])\n",
    "df.index=df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the dataframe to an excel file\n",
    "\n",
    "writer=pd.ExcelWriter('Top300Cryptocurrencies_13JUN2023.xlsx')\n",
    "df.to_excel(writer, index=False, sheet_name='Top300Cryptocurrencies')\n",
    "\n",
    "#Dynamically adjust all the column widths\n",
    "\n",
    "for column in df:\n",
    "    column_length = max(df[column].astype(str).map(len).max(), len(column))\n",
    "    col_index = df.columns.get_loc(column)\n",
    "    writer.sheets['Top300Cryptocurrencies'].set_column(col_index, col_index, column_length)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
